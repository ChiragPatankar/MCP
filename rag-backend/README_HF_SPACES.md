# ğŸš€ Deploy RAG Backend to Hugging Face Spaces

Hugging Face Spaces is **perfect** for deploying Python/FastAPI applications with ML dependencies!

## âœ… Why Hugging Face Spaces?

- âœ… **Free tier** with generous limits
- âœ… **Full Python 3.11+** support
- âœ… **ML libraries** fully supported (sentence-transformers, chromadb, etc.)
- âœ… **Persistent storage** for vector database
- âœ… **No bundle size limits**
- âœ… **GPU support** available (paid)
- âœ… **Automatic HTTPS** and custom domains
- âœ… **GitHub integration** (auto-deploy on push)

## ğŸ“‹ Prerequisites

1. **Hugging Face Account**: Sign up at [huggingface.co](https://huggingface.co)
2. **GitHub Repository**: Your code should be in a GitHub repository
3. **Gemini API Key**: Get from [Google AI Studio](https://aistudio.google.com/app/apikey)

## ğŸš€ Step-by-Step Deployment

### Step 1: Prepare Your Repository

Your `rag-backend/` directory should contain:
- âœ… `app.py` - Entry point (already created)
- âœ… `requirements.txt` - Dependencies
- âœ… `app/main.py` - FastAPI application
- âœ… All other application files

### Step 2: Create Hugging Face Space

1. Go to [Hugging Face Spaces](https://huggingface.co/spaces)
2. Click **"Create new Space"**
3. Configure:
   - **Owner**: Your username
   - **Space name**: `clientsphere-rag-backend` (or your choice)
   - **SDK**: **Docker** (recommended) or **Gradio** (if you want UI)
   - **Hardware**: 
     - **CPU basic** (free) - Good for testing
     - **CPU upgrade** (paid) - Better performance
     - **GPU** (paid) - For heavy ML workloads

### Step 3: Connect GitHub Repository

1. In Space creation, select **"Repository"** as source
2. Choose your GitHub repository
3. Set **Repository path** to: `rag-backend/` (subdirectory)
4. Click **"Create Space"**

### Step 4: Configure Environment Variables

1. Go to your Space's **Settings** tab
2. Scroll to **"Repository secrets"** or **"Variables"**
3. Add these secrets:

**Required:**
```
GEMINI_API_KEY=your_gemini_api_key_here
ENV=prod
LLM_PROVIDER=gemini
```

**Optional (but recommended):**
```
ALLOWED_ORIGINS=https://main.clientsphere.pages.dev,https://abaa49a3.clientsphere.pages.dev
JWT_SECRET=your_secure_jwt_secret
DEBUG=false
```

### Step 5: Configure Docker (if using Docker SDK)

If you selected **Docker** SDK, Hugging Face will use your `Dockerfile`.

**Your existing `Dockerfile` should work!** It's already configured correctly.

### Step 6: Alternative - Use app.py (Simpler)

If you want to use the simpler `app.py` approach:

1. In Space settings, set:
   - **SDK**: **Gradio** or **Streamlit** (but we'll override)
   - **App file**: `app.py`

2. Hugging Face will automatically:
   - Install dependencies from `requirements.txt`
   - Run `python app.py`
   - Expose on port 7860

### Step 7: Deploy!

1. **Push to GitHub** (if not already):
   ```bash
   git add rag-backend/app.py
   git commit -m "Add Hugging Face Spaces entry point"
   git push origin main
   ```

2. **Hugging Face will auto-deploy** from your GitHub repo!

3. **Wait for build** (5-10 minutes first time, faster after)

4. **Your Space URL**: `https://your-username-clientsphere-rag-backend.hf.space`

## ğŸ”§ Configuration Options

### Option A: Docker (Recommended)

**Advantages:**
- Full control over environment
- Can customize Python version
- Better for production

**Setup:**
- Use existing `Dockerfile`
- Hugging Face will build and run it
- Exposes on port 7860 automatically

### Option B: app.py (Simpler)

**Advantages:**
- Simpler setup
- Faster builds
- Good for development

**Setup:**
- Create `app.py` in `rag-backend/` (already done)
- Hugging Face runs it automatically

## ğŸ“ Environment Variables Reference

| Variable | Required | Description |
|----------|----------|-------------|
| `GEMINI_API_KEY` | âœ… Yes | Your Google Gemini API key |
| `ENV` | âœ… Yes | Set to `prod` for production |
| `LLM_PROVIDER` | âœ… Yes | `gemini` or `openai` |
| `ALLOWED_ORIGINS` | âš ï¸ Recommended | CORS allowed origins (comma-separated) |
| `JWT_SECRET` | âš ï¸ Recommended | JWT secret for authentication |
| `DEBUG` | âŒ Optional | Set to `false` in production |
| `OPENAI_API_KEY` | âŒ Optional | If using OpenAI instead of Gemini |

## ğŸŒ CORS Configuration

After deployment, update `ALLOWED_ORIGINS` to include:
- Your Cloudflare Pages frontend URL
- Your Cloudflare Workers backend URL
- Any other origins that need access

Example:
```
ALLOWED_ORIGINS=https://main.clientsphere.pages.dev,https://mcp-backend.officialchiragp1605.workers.dev
```

## ğŸ”„ Updating Deployment

**Automatic (Recommended):**
- Push to GitHub â†’ Hugging Face auto-deploys

**Manual:**
- Go to Space â†’ Settings â†’ "Rebuild Space"

## ğŸ“Š Resource Limits

### Free Tier:
- âœ… **CPU**: Basic (sufficient for RAG)
- âœ… **Storage**: 50GB (plenty for vector DB)
- âœ… **Memory**: 16GB RAM
- âœ… **Build time**: 20 minutes
- âœ… **Sleep after inactivity**: 48 hours (wakes on request)

### Paid Tiers:
- **CPU upgrade**: Better performance
- **GPU**: For heavy ML workloads
- **No sleep**: Always-on service

## ğŸ§ª Testing Deployment

After deployment, test your endpoints:

```bash
# Health check
curl https://your-username-clientsphere-rag-backend.hf.space/health/live

# KB Stats (with auth)
curl https://your-username-clientsphere-rag-backend.hf.space/kb/stats?kb_id=default&tenant_id=test&user_id=test
```

## ğŸ”— Update Frontend

After deployment, update Cloudflare Pages environment variable:

```
VITE_RAG_API_URL=https://your-username-clientsphere-rag-backend.hf.space
```

Then redeploy frontend:
```bash
npm run build
npx wrangler pages deploy dist --project-name=clientsphere
```

## âœ… Advantages Over Render

| Feature | Hugging Face Spaces | Render |
|---------|-------------------|--------|
| Free Tier | âœ… Generous | âš ï¸ Limited |
| ML Libraries | âœ… Full support | âœ… Full support |
| Auto-deploy | âœ… GitHub integration | âœ… GitHub integration |
| Storage | âœ… 50GB free | âš ï¸ Limited |
| Sleep Mode | âœ… Wakes on request | âŒ No sleep mode |
| GPU Support | âœ… Available | âŒ Not available |
| Community | âœ… Large ML community | âš ï¸ Smaller |

## ğŸ¯ Summary

1. âœ… Create Hugging Face Space
2. âœ… Connect GitHub repository (rag-backend/)
3. âœ… Set environment variables
4. âœ… Deploy (automatic on push)
5. âœ… Update frontend `VITE_RAG_API_URL`
6. âœ… Test and enjoy!

**Your RAG backend will be live at:**
`https://your-username-clientsphere-rag-backend.hf.space`

---

**Need help?** Check [Hugging Face Spaces Docs](https://huggingface.co/docs/hub/spaces)

